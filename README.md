# Proyecto Final de Miner铆a de Datos: Predicci贸n de Supervivencia en C谩ncer de Mama

Este repositorio contiene el c贸digo y la documentaci贸n del trabajo final de la asignatura de Miner铆a de Datos. El objetivo principal del proyecto es desarrollar y comparar diversos modelos predictivos para determinar el pron贸stico de supervivencia ("Vivo" o "Exitus") en pacientes diagnosticados con c谩ncer de mama.

##  Descripci贸n del Proyecto

El an谩lisis se centra en un conjunto de datos cl铆nicos (`exam_dataset_24.xlsx`) que incluye variables demogr谩ficas, patol贸gicas y de tratamiento. A trav茅s de un flujo de trabajo riguroso de miner铆a de datos, se busca identificar los factores m谩s influyentes y el algoritmo m谩s preciso para la clasificaci贸n cl铆nica.

### Demo Interactiva
Se ha desplegado una aplicaci贸n Shiny para interactuar con los resultados del modelo:
[Ver Aplicaci贸n Shiny](https://z4u3qf-juan0ignacio-soriano0mu0oz.shinyapps.io/aplicacion/)

## Metodolog铆a

El flujo de trabajo abarca las siguientes etapas:

1.  **Preprocesamiento de Datos:**
    * Limpieza de valores err贸neos y tratamiento de valores perdidos (NAs).
    * Transformaci贸n de variables: categorizaci贸n de edad, extracci贸n del a帽o de diagn贸stico, y binarizaci贸n de la variable objetivo (`ESTADO_ACTUAL`).
    * Agrupaci贸n de estadios del c谩ncer para mejorar la generalizaci贸n.

2.  **An谩lisis Exploratorio (EDA):**
    * Estudio de la distribuci贸n de variables clave como Ki-67, Ganglios, Histolog铆a y Estado Actual.

3.  **Selecci贸n de Caracter铆sticas:**
    * Se probaron m茅todos de filtrado (**Chi-squared**), m茅todos **Wrapper** (StepAIC backward/forward) y fuerza bruta (limitada por coste computacional).

4.  **Balanceo de Clases:**
    * Implementaci贸n de t茅cnicas de **Oversampling** y **Undersampling** para mitigar el desbalanceo en la variable objetivo.

5.  **Validaci贸n de Modelos:**
    * Uso de **Validaci贸n Cruzada 5x2** (5 repeticiones de 2-fold cross-validation) para asegurar la robustez de los resultados y evitar el sobreajuste.

## Modelos Evaluados

Se entrenaron y compararon los siguientes algoritmos de clasificaci贸n supervisada:

* **Redes Neuronales (Neural Networks):** Ajuste de tama帽o de capa oculta y *weight decay*.
* **M谩quinas de Vector Soporte (SVM):** Prueba con kernel radial, variando Costo y Gamma.
* **rboles de Decisi贸n (Decision Trees):** Optimizaci贸n de par谩metros de complejidad (cp) y profundidad.
* **k-Vecinos M谩s Cercanos (k-NN):** B煤squeda del *k* 贸ptimo.
* **Naive Bayes:** Evaluaci贸n con y sin estimaci贸n de kernel.
* **Random Forest:** Ajuste de n煤mero de 谩rboles (*ntree*) y variables por nodo (*mtry*).
* **AdaBoost:** Boosting sobre modelos lineales generalizados.

## Resultados Destacados

Tras la experimentaci贸n exhaustiva, se obtuvieron las siguientes conclusiones:

* **Mejor Desempe帽o:** Los modelos de **Random Forest** (AUC ~0.81) y **Naive Bayes** (AUC ~0.79) mostraron la mejor capacidad de discriminaci贸n.
* **Variables Relevantes:** Las variables que consistentemente mostraron mayor poder predictivo fueron: *A帽o de diagn贸stico*, *Edad*, *Estadio*, *Fenotipo* y *Ganglios*.
* **SVM:** Logr贸 un AUC competitivo (~0.75) utilizando un coste alto y un gamma bajo para controlar el sobreajuste.

## Tecnolog铆as Utilizadas

* **Lenguaje:** R
* **Librer铆as Principales:** `caret`, `pROC`, `nnet`, `e1071`, `randomForest`, `mboost`, `FSelector`, `ggplot2`, `dplyr`.

## 锔 Autor

* **Juan** - *Trabajo Final de Miner铆a de Datos (2024)*
